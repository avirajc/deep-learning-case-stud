{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diamonds assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR5dW__zGRzX"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Cx0gmWYbGg6X",
        "outputId": "4c986bc4-b899-4ae0-d19d-cf28d01f3062"
      },
      "source": [
        "df=pd.read_csv(\"/content/diamonds.csv\")\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>carat</th>\n",
              "      <th>cut</th>\n",
              "      <th>color</th>\n",
              "      <th>clarity</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>price</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.23</td>\n",
              "      <td>Ideal</td>\n",
              "      <td>E</td>\n",
              "      <td>SI2</td>\n",
              "      <td>61.5</td>\n",
              "      <td>55.0</td>\n",
              "      <td>326</td>\n",
              "      <td>3.95</td>\n",
              "      <td>3.98</td>\n",
              "      <td>2.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>Premium</td>\n",
              "      <td>E</td>\n",
              "      <td>SI1</td>\n",
              "      <td>59.8</td>\n",
              "      <td>61.0</td>\n",
              "      <td>326</td>\n",
              "      <td>3.89</td>\n",
              "      <td>3.84</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.23</td>\n",
              "      <td>Good</td>\n",
              "      <td>E</td>\n",
              "      <td>VS1</td>\n",
              "      <td>56.9</td>\n",
              "      <td>65.0</td>\n",
              "      <td>327</td>\n",
              "      <td>4.05</td>\n",
              "      <td>4.07</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.29</td>\n",
              "      <td>Premium</td>\n",
              "      <td>I</td>\n",
              "      <td>VS2</td>\n",
              "      <td>62.4</td>\n",
              "      <td>58.0</td>\n",
              "      <td>334</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4.23</td>\n",
              "      <td>2.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.31</td>\n",
              "      <td>Good</td>\n",
              "      <td>J</td>\n",
              "      <td>SI2</td>\n",
              "      <td>63.3</td>\n",
              "      <td>58.0</td>\n",
              "      <td>335</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.35</td>\n",
              "      <td>2.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  carat      cut color clarity  ...  table  price     x     y     z\n",
              "0           1   0.23    Ideal     E     SI2  ...   55.0    326  3.95  3.98  2.43\n",
              "1           2   0.21  Premium     E     SI1  ...   61.0    326  3.89  3.84  2.31\n",
              "2           3   0.23     Good     E     VS1  ...   65.0    327  4.05  4.07  2.31\n",
              "3           4   0.29  Premium     I     VS2  ...   58.0    334  4.20  4.23  2.63\n",
              "4           5   0.31     Good     J     SI2  ...   58.0    335  4.34  4.35  2.75\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV7WhIIaGrBQ",
        "outputId": "b68e5e3b-12f9-4391-c35c-46dc5a519635"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 53940 entries, 0 to 53939\n",
            "Data columns (total 11 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Unnamed: 0  53940 non-null  int64  \n",
            " 1   carat       53940 non-null  float64\n",
            " 2   cut         53940 non-null  object \n",
            " 3   color       53940 non-null  object \n",
            " 4   clarity     53940 non-null  object \n",
            " 5   depth       53940 non-null  float64\n",
            " 6   table       53940 non-null  float64\n",
            " 7   price       53940 non-null  int64  \n",
            " 8   x           53940 non-null  float64\n",
            " 9   y           53940 non-null  float64\n",
            " 10  z           53940 non-null  float64\n",
            "dtypes: float64(6), int64(2), object(3)\n",
            "memory usage: 4.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt27ibMYGrCl",
        "outputId": "53046fcc-aecb-40ea-ed21-cfe5345037f4"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0    0\n",
              "carat         0\n",
              "cut           0\n",
              "color         0\n",
              "clarity       0\n",
              "depth         0\n",
              "table         0\n",
              "price         0\n",
              "x             0\n",
              "y             0\n",
              "z             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "fZAZtm-tGrGf",
        "outputId": "e854916d-d1df-4efd-8292-eeb4d86c52d7"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>carat</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>price</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>53940.000000</td>\n",
              "      <td>53940.000000</td>\n",
              "      <td>53940.000000</td>\n",
              "      <td>53940.000000</td>\n",
              "      <td>53940.000000</td>\n",
              "      <td>53940.000000</td>\n",
              "      <td>53940.000000</td>\n",
              "      <td>53940.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>26970.500000</td>\n",
              "      <td>0.797940</td>\n",
              "      <td>61.749405</td>\n",
              "      <td>57.457184</td>\n",
              "      <td>3932.799722</td>\n",
              "      <td>5.731157</td>\n",
              "      <td>5.734526</td>\n",
              "      <td>3.538734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>15571.281097</td>\n",
              "      <td>0.474011</td>\n",
              "      <td>1.432621</td>\n",
              "      <td>2.234491</td>\n",
              "      <td>3989.439738</td>\n",
              "      <td>1.121761</td>\n",
              "      <td>1.142135</td>\n",
              "      <td>0.705699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>326.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>13485.750000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>950.000000</td>\n",
              "      <td>4.710000</td>\n",
              "      <td>4.720000</td>\n",
              "      <td>2.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>26970.500000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>61.800000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>2401.000000</td>\n",
              "      <td>5.700000</td>\n",
              "      <td>5.710000</td>\n",
              "      <td>3.530000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>40455.250000</td>\n",
              "      <td>1.040000</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>5324.250000</td>\n",
              "      <td>6.540000</td>\n",
              "      <td>6.540000</td>\n",
              "      <td>4.040000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>53940.000000</td>\n",
              "      <td>5.010000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>18823.000000</td>\n",
              "      <td>10.740000</td>\n",
              "      <td>58.900000</td>\n",
              "      <td>31.800000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0         carat  ...             y             z\n",
              "count  53940.000000  53940.000000  ...  53940.000000  53940.000000\n",
              "mean   26970.500000      0.797940  ...      5.734526      3.538734\n",
              "std    15571.281097      0.474011  ...      1.142135      0.705699\n",
              "min        1.000000      0.200000  ...      0.000000      0.000000\n",
              "25%    13485.750000      0.400000  ...      4.720000      2.910000\n",
              "50%    26970.500000      0.700000  ...      5.710000      3.530000\n",
              "75%    40455.250000      1.040000  ...      6.540000      4.040000\n",
              "max    53940.000000      5.010000  ...     58.900000     31.800000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "yCad5XWAGrIW",
        "outputId": "c9ac0693-e5c0-4fe5-df88-c8830de04662"
      },
      "source": [
        "df.corr()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>carat</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>price</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.377983</td>\n",
              "      <td>-0.034800</td>\n",
              "      <td>-0.100830</td>\n",
              "      <td>-0.306873</td>\n",
              "      <td>-0.405440</td>\n",
              "      <td>-0.395843</td>\n",
              "      <td>-0.399208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carat</th>\n",
              "      <td>-0.377983</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.028224</td>\n",
              "      <td>0.181618</td>\n",
              "      <td>0.921591</td>\n",
              "      <td>0.975094</td>\n",
              "      <td>0.951722</td>\n",
              "      <td>0.953387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>depth</th>\n",
              "      <td>-0.034800</td>\n",
              "      <td>0.028224</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.295779</td>\n",
              "      <td>-0.010647</td>\n",
              "      <td>-0.025289</td>\n",
              "      <td>-0.029341</td>\n",
              "      <td>0.094924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>table</th>\n",
              "      <td>-0.100830</td>\n",
              "      <td>0.181618</td>\n",
              "      <td>-0.295779</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.127134</td>\n",
              "      <td>0.195344</td>\n",
              "      <td>0.183760</td>\n",
              "      <td>0.150929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>-0.306873</td>\n",
              "      <td>0.921591</td>\n",
              "      <td>-0.010647</td>\n",
              "      <td>0.127134</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.884435</td>\n",
              "      <td>0.865421</td>\n",
              "      <td>0.861249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x</th>\n",
              "      <td>-0.405440</td>\n",
              "      <td>0.975094</td>\n",
              "      <td>-0.025289</td>\n",
              "      <td>0.195344</td>\n",
              "      <td>0.884435</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.974701</td>\n",
              "      <td>0.970772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y</th>\n",
              "      <td>-0.395843</td>\n",
              "      <td>0.951722</td>\n",
              "      <td>-0.029341</td>\n",
              "      <td>0.183760</td>\n",
              "      <td>0.865421</td>\n",
              "      <td>0.974701</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.952006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>z</th>\n",
              "      <td>-0.399208</td>\n",
              "      <td>0.953387</td>\n",
              "      <td>0.094924</td>\n",
              "      <td>0.150929</td>\n",
              "      <td>0.861249</td>\n",
              "      <td>0.970772</td>\n",
              "      <td>0.952006</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Unnamed: 0     carat     depth  ...         x         y         z\n",
              "Unnamed: 0    1.000000 -0.377983 -0.034800  ... -0.405440 -0.395843 -0.399208\n",
              "carat        -0.377983  1.000000  0.028224  ...  0.975094  0.951722  0.953387\n",
              "depth        -0.034800  0.028224  1.000000  ... -0.025289 -0.029341  0.094924\n",
              "table        -0.100830  0.181618 -0.295779  ...  0.195344  0.183760  0.150929\n",
              "price        -0.306873  0.921591 -0.010647  ...  0.884435  0.865421  0.861249\n",
              "x            -0.405440  0.975094 -0.025289  ...  1.000000  0.974701  0.970772\n",
              "y            -0.395843  0.951722 -0.029341  ...  0.974701  1.000000  0.952006\n",
              "z            -0.399208  0.953387  0.094924  ...  0.970772  0.952006  1.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfyx18aeG80v"
      },
      "source": [
        "x=df.iloc[:,1:-4].values\n",
        "y=df.iloc[:,-4].values\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJnYHq_WQEMg",
        "outputId": "dd9bbf71-c884-400e-8f2c-8e2aecd00876"
      },
      "source": [
        "x"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.23, 'Ideal', 'E', 'SI2', 61.5, 55.0],\n",
              "       [0.21, 'Premium', 'E', 'SI1', 59.8, 61.0],\n",
              "       [0.23, 'Good', 'E', 'VS1', 56.9, 65.0],\n",
              "       ...,\n",
              "       [0.7, 'Very Good', 'D', 'SI1', 62.8, 60.0],\n",
              "       [0.86, 'Premium', 'H', 'SI2', 61.0, 58.0],\n",
              "       [0.75, 'Ideal', 'D', 'SI2', 62.2, 55.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HykgZ14BP-Qy"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "x[:,1]=le.fit_transform(x[:,1])\n",
        "le1 = LabelEncoder()\n",
        "x[:,2]=le1.fit_transform(x[:,2])\n",
        "le2 = LabelEncoder()\n",
        "x[:,3]=le2.fit_transform(x[:,3])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXBSpGwqORRz"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x = sc.fit_transform(x)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUYLEvA0NzRv"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,random_state=1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He0TPGNsN9BO",
        "outputId": "91871ef2-19e3-476c-ccc3-bc397b5791c2"
      },
      "source": [
        "#Model Creation\n",
        "#step1: Initiaze the network\n",
        "ann = tf.keras.Sequential()\n",
        "#step2: Add Layer to the network\n",
        "ann.add(tf.keras.layers.Dense(units=7,activation='relu'))\n",
        "#step3: Add output layer\n",
        "ann.add(tf.keras.layers.Dense(units=1,activation='linear'))\n",
        "#step4: establishing connection between layer\n",
        "ann.compile(optimizer='adam',loss=\"mse\")\n",
        "#step5: train model\n",
        "ann.fit(xtrain,ytrain,epochs=300,batch_size=30)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "1259/1259 [==============================] - 2s 978us/step - loss: 31590802.0000\n",
            "Epoch 2/300\n",
            "1259/1259 [==============================] - 1s 949us/step - loss: 30890322.0000\n",
            "Epoch 3/300\n",
            "1259/1259 [==============================] - 1s 936us/step - loss: 29707074.0000\n",
            "Epoch 4/300\n",
            "1259/1259 [==============================] - 1s 941us/step - loss: 28205850.0000\n",
            "Epoch 5/300\n",
            "1259/1259 [==============================] - 1s 913us/step - loss: 26474552.0000\n",
            "Epoch 6/300\n",
            "1259/1259 [==============================] - 1s 938us/step - loss: 24588834.0000\n",
            "Epoch 7/300\n",
            "1259/1259 [==============================] - 1s 977us/step - loss: 22607710.0000\n",
            "Epoch 8/300\n",
            "1259/1259 [==============================] - 1s 948us/step - loss: 20596668.0000\n",
            "Epoch 9/300\n",
            "1259/1259 [==============================] - 1s 946us/step - loss: 18597654.0000\n",
            "Epoch 10/300\n",
            "1259/1259 [==============================] - 1s 941us/step - loss: 16652184.0000\n",
            "Epoch 11/300\n",
            "1259/1259 [==============================] - 1s 935us/step - loss: 14790292.0000\n",
            "Epoch 12/300\n",
            "1259/1259 [==============================] - 1s 942us/step - loss: 13035382.0000\n",
            "Epoch 13/300\n",
            "1259/1259 [==============================] - 1s 960us/step - loss: 11378990.0000\n",
            "Epoch 14/300\n",
            "1259/1259 [==============================] - 1s 950us/step - loss: 9816724.0000\n",
            "Epoch 15/300\n",
            "1259/1259 [==============================] - 1s 933us/step - loss: 8335751.0000\n",
            "Epoch 16/300\n",
            "1259/1259 [==============================] - 1s 981us/step - loss: 6966218.5000\n",
            "Epoch 17/300\n",
            "1259/1259 [==============================] - 1s 928us/step - loss: 5736765.0000\n",
            "Epoch 18/300\n",
            "1259/1259 [==============================] - 1s 940us/step - loss: 4670084.0000\n",
            "Epoch 19/300\n",
            "1259/1259 [==============================] - 1s 946us/step - loss: 3788779.7500\n",
            "Epoch 20/300\n",
            "1259/1259 [==============================] - 1s 952us/step - loss: 3103916.5000\n",
            "Epoch 21/300\n",
            "1259/1259 [==============================] - 1s 947us/step - loss: 2614619.2500\n",
            "Epoch 22/300\n",
            "1259/1259 [==============================] - 1s 950us/step - loss: 2283023.0000\n",
            "Epoch 23/300\n",
            "1259/1259 [==============================] - 1s 950us/step - loss: 2065406.7500\n",
            "Epoch 24/300\n",
            "1259/1259 [==============================] - 1s 972us/step - loss: 1923153.2500\n",
            "Epoch 25/300\n",
            "1259/1259 [==============================] - 1s 958us/step - loss: 1829692.6250\n",
            "Epoch 26/300\n",
            "1259/1259 [==============================] - 1s 941us/step - loss: 1768612.5000\n",
            "Epoch 27/300\n",
            "1259/1259 [==============================] - 1s 958us/step - loss: 1727935.0000\n",
            "Epoch 28/300\n",
            "1259/1259 [==============================] - 1s 939us/step - loss: 1699712.6250\n",
            "Epoch 29/300\n",
            "1259/1259 [==============================] - 1s 943us/step - loss: 1679801.6250\n",
            "Epoch 30/300\n",
            "1259/1259 [==============================] - 1s 933us/step - loss: 1665481.3750\n",
            "Epoch 31/300\n",
            "1259/1259 [==============================] - 1s 939us/step - loss: 1654896.1250\n",
            "Epoch 32/300\n",
            "1259/1259 [==============================] - 1s 943us/step - loss: 1647034.1250\n",
            "Epoch 33/300\n",
            "1259/1259 [==============================] - 1s 949us/step - loss: 1641078.8750\n",
            "Epoch 34/300\n",
            "1259/1259 [==============================] - 1s 958us/step - loss: 1636240.8750\n",
            "Epoch 35/300\n",
            "1259/1259 [==============================] - 1s 944us/step - loss: 1632364.3750\n",
            "Epoch 36/300\n",
            "1259/1259 [==============================] - 1s 944us/step - loss: 1629171.3750\n",
            "Epoch 37/300\n",
            "1259/1259 [==============================] - 1s 964us/step - loss: 1626295.8750\n",
            "Epoch 38/300\n",
            "1259/1259 [==============================] - 1s 949us/step - loss: 1623719.1250\n",
            "Epoch 39/300\n",
            "1259/1259 [==============================] - 1s 953us/step - loss: 1621400.0000\n",
            "Epoch 40/300\n",
            "1259/1259 [==============================] - 1s 976us/step - loss: 1619288.0000\n",
            "Epoch 41/300\n",
            "1259/1259 [==============================] - 1s 977us/step - loss: 1617197.2500\n",
            "Epoch 42/300\n",
            "1259/1259 [==============================] - 1s 943us/step - loss: 1615259.2500\n",
            "Epoch 43/300\n",
            "1259/1259 [==============================] - 1s 960us/step - loss: 1613362.0000\n",
            "Epoch 44/300\n",
            "1259/1259 [==============================] - 1s 946us/step - loss: 1611523.6250\n",
            "Epoch 45/300\n",
            "1259/1259 [==============================] - 1s 962us/step - loss: 1609666.0000\n",
            "Epoch 46/300\n",
            "1259/1259 [==============================] - 1s 944us/step - loss: 1607898.3750\n",
            "Epoch 47/300\n",
            "1259/1259 [==============================] - 1s 948us/step - loss: 1606126.1250\n",
            "Epoch 48/300\n",
            "1259/1259 [==============================] - 1s 940us/step - loss: 1604351.1250\n",
            "Epoch 49/300\n",
            "1259/1259 [==============================] - 1s 966us/step - loss: 1602628.1250\n",
            "Epoch 50/300\n",
            "1259/1259 [==============================] - 1s 955us/step - loss: 1600895.6250\n",
            "Epoch 51/300\n",
            "1259/1259 [==============================] - 1s 983us/step - loss: 1599151.1250\n",
            "Epoch 52/300\n",
            "1259/1259 [==============================] - 1s 975us/step - loss: 1597571.7500\n",
            "Epoch 53/300\n",
            "1259/1259 [==============================] - 1s 958us/step - loss: 1595866.8750\n",
            "Epoch 54/300\n",
            "1259/1259 [==============================] - 1s 950us/step - loss: 1594151.6250\n",
            "Epoch 55/300\n",
            "1259/1259 [==============================] - 1s 949us/step - loss: 1592454.2500\n",
            "Epoch 56/300\n",
            "1259/1259 [==============================] - 1s 952us/step - loss: 1590669.0000\n",
            "Epoch 57/300\n",
            "1259/1259 [==============================] - 1s 944us/step - loss: 1589110.3750\n",
            "Epoch 58/300\n",
            "1259/1259 [==============================] - 1s 951us/step - loss: 1587417.2500\n",
            "Epoch 59/300\n",
            "1259/1259 [==============================] - 1s 956us/step - loss: 1585629.6250\n",
            "Epoch 60/300\n",
            "1259/1259 [==============================] - 1s 947us/step - loss: 1583944.5000\n",
            "Epoch 61/300\n",
            "1259/1259 [==============================] - 1s 960us/step - loss: 1582365.6250\n",
            "Epoch 62/300\n",
            "1259/1259 [==============================] - 1s 943us/step - loss: 1580635.3750\n",
            "Epoch 63/300\n",
            "1259/1259 [==============================] - 1s 965us/step - loss: 1578875.0000\n",
            "Epoch 64/300\n",
            "1259/1259 [==============================] - 1s 946us/step - loss: 1577284.2500\n",
            "Epoch 65/300\n",
            "1259/1259 [==============================] - 1s 951us/step - loss: 1575487.3750\n",
            "Epoch 66/300\n",
            "1259/1259 [==============================] - 1s 959us/step - loss: 1573833.2500\n",
            "Epoch 67/300\n",
            "1259/1259 [==============================] - 1s 954us/step - loss: 1572137.0000\n",
            "Epoch 68/300\n",
            "1259/1259 [==============================] - 1s 960us/step - loss: 1570382.8750\n",
            "Epoch 69/300\n",
            "1259/1259 [==============================] - 1s 947us/step - loss: 1568640.3750\n",
            "Epoch 70/300\n",
            "1259/1259 [==============================] - 1s 963us/step - loss: 1566911.2500\n",
            "Epoch 71/300\n",
            "1259/1259 [==============================] - 1s 989us/step - loss: 1565122.5000\n",
            "Epoch 72/300\n",
            "1259/1259 [==============================] - 1s 974us/step - loss: 1563330.8750\n",
            "Epoch 73/300\n",
            "1259/1259 [==============================] - 1s 971us/step - loss: 1561525.8750\n",
            "Epoch 74/300\n",
            "1259/1259 [==============================] - 1s 970us/step - loss: 1559817.3750\n",
            "Epoch 75/300\n",
            "1259/1259 [==============================] - 1s 972us/step - loss: 1558050.6250\n",
            "Epoch 76/300\n",
            "1259/1259 [==============================] - 1s 972us/step - loss: 1556115.2500\n",
            "Epoch 77/300\n",
            "1259/1259 [==============================] - 1s 957us/step - loss: 1554411.8750\n",
            "Epoch 78/300\n",
            "1259/1259 [==============================] - 1s 948us/step - loss: 1552367.8750\n",
            "Epoch 79/300\n",
            "1259/1259 [==============================] - 1s 972us/step - loss: 1550628.6250\n",
            "Epoch 80/300\n",
            "1259/1259 [==============================] - 1s 953us/step - loss: 1548709.5000\n",
            "Epoch 81/300\n",
            "1259/1259 [==============================] - 1s 963us/step - loss: 1546796.3750\n",
            "Epoch 82/300\n",
            "1259/1259 [==============================] - 1s 978us/step - loss: 1545008.6250\n",
            "Epoch 83/300\n",
            "1259/1259 [==============================] - 1s 968us/step - loss: 1543165.0000\n",
            "Epoch 84/300\n",
            "1259/1259 [==============================] - 1s 982us/step - loss: 1541302.7500\n",
            "Epoch 85/300\n",
            "1259/1259 [==============================] - 1s 948us/step - loss: 1539501.6250\n",
            "Epoch 86/300\n",
            "1259/1259 [==============================] - 1s 941us/step - loss: 1537632.8750\n",
            "Epoch 87/300\n",
            "1259/1259 [==============================] - 1s 934us/step - loss: 1535816.7500\n",
            "Epoch 88/300\n",
            "1259/1259 [==============================] - 1s 982us/step - loss: 1534002.0000\n",
            "Epoch 89/300\n",
            "1259/1259 [==============================] - 1s 950us/step - loss: 1532090.1250\n",
            "Epoch 90/300\n",
            "1259/1259 [==============================] - 1s 979us/step - loss: 1530294.7500\n",
            "Epoch 91/300\n",
            "1259/1259 [==============================] - 1s 984us/step - loss: 1528530.1250\n",
            "Epoch 92/300\n",
            "1259/1259 [==============================] - 1s 980us/step - loss: 1526708.6250\n",
            "Epoch 93/300\n",
            "1259/1259 [==============================] - 1s 951us/step - loss: 1524795.1250\n",
            "Epoch 94/300\n",
            "1259/1259 [==============================] - 1s 980us/step - loss: 1522947.8750\n",
            "Epoch 95/300\n",
            "1259/1259 [==============================] - 1s 977us/step - loss: 1521108.2500\n",
            "Epoch 96/300\n",
            "1259/1259 [==============================] - 1s 977us/step - loss: 1519297.6250\n",
            "Epoch 97/300\n",
            "1259/1259 [==============================] - 1s 951us/step - loss: 1517541.2500\n",
            "Epoch 98/300\n",
            "1259/1259 [==============================] - 1s 961us/step - loss: 1515695.0000\n",
            "Epoch 99/300\n",
            "1259/1259 [==============================] - 1s 976us/step - loss: 1513993.1250\n",
            "Epoch 100/300\n",
            "1259/1259 [==============================] - 1s 966us/step - loss: 1512081.1250\n",
            "Epoch 101/300\n",
            "1259/1259 [==============================] - 1s 948us/step - loss: 1510349.2500\n",
            "Epoch 102/300\n",
            "1259/1259 [==============================] - 1s 957us/step - loss: 1508542.3750\n",
            "Epoch 103/300\n",
            "1259/1259 [==============================] - 1s 949us/step - loss: 1506758.1250\n",
            "Epoch 104/300\n",
            "1259/1259 [==============================] - 1s 961us/step - loss: 1504930.3750\n",
            "Epoch 105/300\n",
            "1259/1259 [==============================] - 1s 976us/step - loss: 1503120.2500\n",
            "Epoch 106/300\n",
            "1259/1259 [==============================] - 1s 956us/step - loss: 1501305.1250\n",
            "Epoch 107/300\n",
            "1259/1259 [==============================] - 1s 953us/step - loss: 1499470.6250\n",
            "Epoch 108/300\n",
            "1259/1259 [==============================] - 1s 972us/step - loss: 1497696.6250\n",
            "Epoch 109/300\n",
            "1259/1259 [==============================] - 1s 974us/step - loss: 1496025.0000\n",
            "Epoch 110/300\n",
            "1259/1259 [==============================] - 1s 972us/step - loss: 1494231.0000\n",
            "Epoch 111/300\n",
            "1259/1259 [==============================] - 1s 981us/step - loss: 1492431.3750\n",
            "Epoch 112/300\n",
            "1259/1259 [==============================] - 1s 993us/step - loss: 1490779.1250\n",
            "Epoch 113/300\n",
            "1259/1259 [==============================] - 1s 962us/step - loss: 1488962.5000\n",
            "Epoch 114/300\n",
            "1259/1259 [==============================] - 1s 955us/step - loss: 1487327.0000\n",
            "Epoch 115/300\n",
            "1259/1259 [==============================] - 1s 979us/step - loss: 1485559.6250\n",
            "Epoch 116/300\n",
            "1259/1259 [==============================] - 1s 953us/step - loss: 1483917.3750\n",
            "Epoch 117/300\n",
            "1259/1259 [==============================] - 1s 974us/step - loss: 1482037.5000\n",
            "Epoch 118/300\n",
            "1259/1259 [==============================] - 1s 972us/step - loss: 1480334.1250\n",
            "Epoch 119/300\n",
            "1259/1259 [==============================] - 1s 984us/step - loss: 1478647.8750\n",
            "Epoch 120/300\n",
            "1259/1259 [==============================] - 1s 949us/step - loss: 1476937.6250\n",
            "Epoch 121/300\n",
            "1259/1259 [==============================] - 1s 962us/step - loss: 1475272.1250\n",
            "Epoch 122/300\n",
            "1259/1259 [==============================] - 1s 982us/step - loss: 1473584.6250\n",
            "Epoch 123/300\n",
            "1259/1259 [==============================] - 1s 973us/step - loss: 1471970.3750\n",
            "Epoch 124/300\n",
            "1259/1259 [==============================] - 1s 968us/step - loss: 1470391.3750\n",
            "Epoch 125/300\n",
            "1259/1259 [==============================] - 1s 957us/step - loss: 1468751.6250\n",
            "Epoch 126/300\n",
            "1259/1259 [==============================] - 1s 958us/step - loss: 1467256.8750\n",
            "Epoch 127/300\n",
            "1259/1259 [==============================] - 1s 961us/step - loss: 1465698.8750\n",
            "Epoch 128/300\n",
            "1259/1259 [==============================] - 1s 980us/step - loss: 1464132.2500\n",
            "Epoch 129/300\n",
            "1259/1259 [==============================] - 1s 969us/step - loss: 1462675.5000\n",
            "Epoch 130/300\n",
            "1259/1259 [==============================] - 1s 981us/step - loss: 1461166.7500\n",
            "Epoch 131/300\n",
            "1259/1259 [==============================] - 1s 971us/step - loss: 1459663.7500\n",
            "Epoch 132/300\n",
            "1259/1259 [==============================] - 1s 983us/step - loss: 1458259.2500\n",
            "Epoch 133/300\n",
            "1259/1259 [==============================] - 1s 976us/step - loss: 1456801.0000\n",
            "Epoch 134/300\n",
            "1259/1259 [==============================] - 1s 943us/step - loss: 1455416.0000\n",
            "Epoch 135/300\n",
            "1259/1259 [==============================] - 1s 962us/step - loss: 1453978.7500\n",
            "Epoch 136/300\n",
            "1259/1259 [==============================] - 1s 971us/step - loss: 1452566.1250\n",
            "Epoch 137/300\n",
            "1259/1259 [==============================] - 1s 976us/step - loss: 1451229.1250\n",
            "Epoch 138/300\n",
            "1259/1259 [==============================] - 1s 952us/step - loss: 1449855.1250\n",
            "Epoch 139/300\n",
            "1259/1259 [==============================] - 1s 978us/step - loss: 1448525.7500\n",
            "Epoch 140/300\n",
            "1259/1259 [==============================] - 1s 975us/step - loss: 1447247.8750\n",
            "Epoch 141/300\n",
            "1259/1259 [==============================] - 1s 981us/step - loss: 1445771.8750\n",
            "Epoch 142/300\n",
            "1259/1259 [==============================] - 1s 977us/step - loss: 1444421.5000\n",
            "Epoch 143/300\n",
            "1259/1259 [==============================] - 1s 960us/step - loss: 1443163.3750\n",
            "Epoch 144/300\n",
            "1259/1259 [==============================] - 1s 979us/step - loss: 1441734.6250\n",
            "Epoch 145/300\n",
            "1259/1259 [==============================] - 1s 976us/step - loss: 1440585.1250\n",
            "Epoch 146/300\n",
            "1259/1259 [==============================] - 1s 953us/step - loss: 1439341.5000\n",
            "Epoch 147/300\n",
            "1259/1259 [==============================] - 1s 954us/step - loss: 1438061.3750\n",
            "Epoch 148/300\n",
            "1259/1259 [==============================] - 1s 959us/step - loss: 1436947.1250\n",
            "Epoch 149/300\n",
            "1259/1259 [==============================] - 1s 990us/step - loss: 1435784.3750\n",
            "Epoch 150/300\n",
            "1259/1259 [==============================] - 1s 958us/step - loss: 1434658.7500\n",
            "Epoch 151/300\n",
            "1259/1259 [==============================] - 1s 972us/step - loss: 1433471.7500\n",
            "Epoch 152/300\n",
            "1259/1259 [==============================] - 1s 995us/step - loss: 1432502.3750\n",
            "Epoch 153/300\n",
            "1259/1259 [==============================] - 1s 962us/step - loss: 1431350.2500\n",
            "Epoch 154/300\n",
            "1259/1259 [==============================] - 1s 975us/step - loss: 1430276.8750\n",
            "Epoch 155/300\n",
            "1259/1259 [==============================] - 1s 970us/step - loss: 1429223.6250\n",
            "Epoch 156/300\n",
            "1259/1259 [==============================] - 1s 980us/step - loss: 1428220.0000\n",
            "Epoch 157/300\n",
            "1259/1259 [==============================] - 1s 977us/step - loss: 1427235.7500\n",
            "Epoch 158/300\n",
            "1259/1259 [==============================] - 1s 980us/step - loss: 1426272.6250\n",
            "Epoch 159/300\n",
            "1259/1259 [==============================] - 1s 987us/step - loss: 1425203.1250\n",
            "Epoch 160/300\n",
            "1259/1259 [==============================] - 1s 975us/step - loss: 1424335.3750\n",
            "Epoch 161/300\n",
            "1259/1259 [==============================] - 1s 965us/step - loss: 1423406.2500\n",
            "Epoch 162/300\n",
            "1259/1259 [==============================] - 1s 980us/step - loss: 1422513.7500\n",
            "Epoch 163/300\n",
            "1259/1259 [==============================] - 1s 974us/step - loss: 1421668.6250\n",
            "Epoch 164/300\n",
            "1259/1259 [==============================] - 1s 952us/step - loss: 1420853.0000\n",
            "Epoch 165/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1420041.6250\n",
            "Epoch 166/300\n",
            "1259/1259 [==============================] - 1s 984us/step - loss: 1419222.0000\n",
            "Epoch 167/300\n",
            "1259/1259 [==============================] - 1s 982us/step - loss: 1418541.1250\n",
            "Epoch 168/300\n",
            "1259/1259 [==============================] - 1s 989us/step - loss: 1417712.2500\n",
            "Epoch 169/300\n",
            "1259/1259 [==============================] - 1s 977us/step - loss: 1417148.1250\n",
            "Epoch 170/300\n",
            "1259/1259 [==============================] - 1s 1000us/step - loss: 1416501.5000\n",
            "Epoch 171/300\n",
            "1259/1259 [==============================] - 1s 976us/step - loss: 1415850.5000\n",
            "Epoch 172/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1415214.1250\n",
            "Epoch 173/300\n",
            "1259/1259 [==============================] - 1s 984us/step - loss: 1414633.3750\n",
            "Epoch 174/300\n",
            "1259/1259 [==============================] - 1s 971us/step - loss: 1414143.6250\n",
            "Epoch 175/300\n",
            "1259/1259 [==============================] - 1s 989us/step - loss: 1413556.5000\n",
            "Epoch 176/300\n",
            "1259/1259 [==============================] - 1s 982us/step - loss: 1413034.3750\n",
            "Epoch 177/300\n",
            "1259/1259 [==============================] - 1s 978us/step - loss: 1412585.3750\n",
            "Epoch 178/300\n",
            "1259/1259 [==============================] - 1s 977us/step - loss: 1411971.0000\n",
            "Epoch 179/300\n",
            "1259/1259 [==============================] - 1s 990us/step - loss: 1411555.3750\n",
            "Epoch 180/300\n",
            "1259/1259 [==============================] - 1s 971us/step - loss: 1411042.5000\n",
            "Epoch 181/300\n",
            "1259/1259 [==============================] - 1s 955us/step - loss: 1410629.5000\n",
            "Epoch 182/300\n",
            "1259/1259 [==============================] - 1s 981us/step - loss: 1410187.5000\n",
            "Epoch 183/300\n",
            "1259/1259 [==============================] - 1s 982us/step - loss: 1409770.5000\n",
            "Epoch 184/300\n",
            "1259/1259 [==============================] - 1s 993us/step - loss: 1409371.5000\n",
            "Epoch 185/300\n",
            "1259/1259 [==============================] - 1s 962us/step - loss: 1408953.5000\n",
            "Epoch 186/300\n",
            "1259/1259 [==============================] - 1s 981us/step - loss: 1408587.0000\n",
            "Epoch 187/300\n",
            "1259/1259 [==============================] - 1s 985us/step - loss: 1408220.6250\n",
            "Epoch 188/300\n",
            "1259/1259 [==============================] - 1s 990us/step - loss: 1407842.2500\n",
            "Epoch 189/300\n",
            "1259/1259 [==============================] - 1s 981us/step - loss: 1407446.6250\n",
            "Epoch 190/300\n",
            "1259/1259 [==============================] - 1s 973us/step - loss: 1407102.0000\n",
            "Epoch 191/300\n",
            "1259/1259 [==============================] - 1s 968us/step - loss: 1406791.7500\n",
            "Epoch 192/300\n",
            "1259/1259 [==============================] - 1s 997us/step - loss: 1406388.0000\n",
            "Epoch 193/300\n",
            "1259/1259 [==============================] - 1s 979us/step - loss: 1406125.0000\n",
            "Epoch 194/300\n",
            "1259/1259 [==============================] - 1s 994us/step - loss: 1405734.6250\n",
            "Epoch 195/300\n",
            "1259/1259 [==============================] - 1s 997us/step - loss: 1405460.7500\n",
            "Epoch 196/300\n",
            "1259/1259 [==============================] - 1s 986us/step - loss: 1405146.7500\n",
            "Epoch 197/300\n",
            "1259/1259 [==============================] - 1s 974us/step - loss: 1404849.6250\n",
            "Epoch 198/300\n",
            "1259/1259 [==============================] - 1s 979us/step - loss: 1404499.6250\n",
            "Epoch 199/300\n",
            "1259/1259 [==============================] - 1s 978us/step - loss: 1404292.2500\n",
            "Epoch 200/300\n",
            "1259/1259 [==============================] - 1s 952us/step - loss: 1404065.2500\n",
            "Epoch 201/300\n",
            "1259/1259 [==============================] - 1s 985us/step - loss: 1403714.2500\n",
            "Epoch 202/300\n",
            "1259/1259 [==============================] - 1s 956us/step - loss: 1403385.3750\n",
            "Epoch 203/300\n",
            "1259/1259 [==============================] - 1s 985us/step - loss: 1403124.3750\n",
            "Epoch 204/300\n",
            "1259/1259 [==============================] - 1s 984us/step - loss: 1402962.3750\n",
            "Epoch 205/300\n",
            "1259/1259 [==============================] - 1s 990us/step - loss: 1402744.1250\n",
            "Epoch 206/300\n",
            "1259/1259 [==============================] - 1s 972us/step - loss: 1402516.1250\n",
            "Epoch 207/300\n",
            "1259/1259 [==============================] - 1s 976us/step - loss: 1402281.8750\n",
            "Epoch 208/300\n",
            "1259/1259 [==============================] - 1s 992us/step - loss: 1402022.5000\n",
            "Epoch 209/300\n",
            "1259/1259 [==============================] - 1s 986us/step - loss: 1401904.5000\n",
            "Epoch 210/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1401681.3750\n",
            "Epoch 211/300\n",
            "1259/1259 [==============================] - 1s 987us/step - loss: 1401431.2500\n",
            "Epoch 212/300\n",
            "1259/1259 [==============================] - 1s 993us/step - loss: 1401238.6250\n",
            "Epoch 213/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1401040.1250\n",
            "Epoch 214/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1400785.1250\n",
            "Epoch 215/300\n",
            "1259/1259 [==============================] - 1s 989us/step - loss: 1400640.2500\n",
            "Epoch 216/300\n",
            "1259/1259 [==============================] - 1s 992us/step - loss: 1400334.0000\n",
            "Epoch 217/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1400266.6250\n",
            "Epoch 218/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1400037.1250\n",
            "Epoch 219/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1399873.6250\n",
            "Epoch 220/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1399597.7500\n",
            "Epoch 221/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1399502.3750\n",
            "Epoch 222/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1399290.8750\n",
            "Epoch 223/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1399199.5000\n",
            "Epoch 224/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1398966.1250\n",
            "Epoch 225/300\n",
            "1259/1259 [==============================] - 1s 996us/step - loss: 1398823.8750\n",
            "Epoch 226/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1398705.5000\n",
            "Epoch 227/300\n",
            "1259/1259 [==============================] - 1s 970us/step - loss: 1398549.7500\n",
            "Epoch 228/300\n",
            "1259/1259 [==============================] - 1s 984us/step - loss: 1398379.1250\n",
            "Epoch 229/300\n",
            "1259/1259 [==============================] - 1s 997us/step - loss: 1398249.6250\n",
            "Epoch 230/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1398124.6250\n",
            "Epoch 231/300\n",
            "1259/1259 [==============================] - 1s 997us/step - loss: 1397879.1250\n",
            "Epoch 232/300\n",
            "1259/1259 [==============================] - 1s 994us/step - loss: 1397702.0000\n",
            "Epoch 233/300\n",
            "1259/1259 [==============================] - 1s 1000us/step - loss: 1397645.5000\n",
            "Epoch 234/300\n",
            "1259/1259 [==============================] - 1s 993us/step - loss: 1397518.0000\n",
            "Epoch 235/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1397296.2500\n",
            "Epoch 236/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1397239.6250\n",
            "Epoch 237/300\n",
            "1259/1259 [==============================] - 1s 981us/step - loss: 1397073.3750\n",
            "Epoch 238/300\n",
            "1259/1259 [==============================] - 1s 979us/step - loss: 1396944.7500\n",
            "Epoch 239/300\n",
            "1259/1259 [==============================] - 1s 989us/step - loss: 1396820.0000\n",
            "Epoch 240/300\n",
            "1259/1259 [==============================] - 1s 997us/step - loss: 1396669.7500\n",
            "Epoch 241/300\n",
            "1259/1259 [==============================] - 1s 995us/step - loss: 1396492.7500\n",
            "Epoch 242/300\n",
            "1259/1259 [==============================] - 1s 998us/step - loss: 1396431.1250\n",
            "Epoch 243/300\n",
            "1259/1259 [==============================] - 1s 993us/step - loss: 1396219.5000\n",
            "Epoch 244/300\n",
            "1259/1259 [==============================] - 1s 996us/step - loss: 1396182.1250\n",
            "Epoch 245/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1396007.0000\n",
            "Epoch 246/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1395996.6250\n",
            "Epoch 247/300\n",
            "1259/1259 [==============================] - 1s 982us/step - loss: 1395778.1250\n",
            "Epoch 248/300\n",
            "1259/1259 [==============================] - 1s 985us/step - loss: 1395671.0000\n",
            "Epoch 249/300\n",
            "1259/1259 [==============================] - 1s 975us/step - loss: 1395631.8750\n",
            "Epoch 250/300\n",
            "1259/1259 [==============================] - 1s 995us/step - loss: 1395461.3750\n",
            "Epoch 251/300\n",
            "1259/1259 [==============================] - 1s 985us/step - loss: 1395354.8750\n",
            "Epoch 252/300\n",
            "1259/1259 [==============================] - 1s 998us/step - loss: 1395296.3750\n",
            "Epoch 253/300\n",
            "1259/1259 [==============================] - 1s 991us/step - loss: 1395111.1250\n",
            "Epoch 254/300\n",
            "1259/1259 [==============================] - 1s 990us/step - loss: 1395085.1250\n",
            "Epoch 255/300\n",
            "1259/1259 [==============================] - 1s 956us/step - loss: 1394980.8750\n",
            "Epoch 256/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1394871.1250\n",
            "Epoch 257/300\n",
            "1259/1259 [==============================] - 1s 978us/step - loss: 1394746.0000\n",
            "Epoch 258/300\n",
            "1259/1259 [==============================] - 1s 985us/step - loss: 1394688.6250\n",
            "Epoch 259/300\n",
            "1259/1259 [==============================] - 1s 989us/step - loss: 1394427.7500\n",
            "Epoch 260/300\n",
            "1259/1259 [==============================] - 1s 988us/step - loss: 1394490.3750\n",
            "Epoch 261/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1394447.5000\n",
            "Epoch 262/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1394312.2500\n",
            "Epoch 263/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1394215.5000\n",
            "Epoch 264/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1394073.2500\n",
            "Epoch 265/300\n",
            "1259/1259 [==============================] - 1s 991us/step - loss: 1394026.8750\n",
            "Epoch 266/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1393933.2500\n",
            "Epoch 267/300\n",
            "1259/1259 [==============================] - 1s 987us/step - loss: 1393874.3750\n",
            "Epoch 268/300\n",
            "1259/1259 [==============================] - 1s 990us/step - loss: 1393750.8750\n",
            "Epoch 269/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1393670.0000\n",
            "Epoch 270/300\n",
            "1259/1259 [==============================] - 1s 990us/step - loss: 1393628.2500\n",
            "Epoch 271/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1393485.8750\n",
            "Epoch 272/300\n",
            "1259/1259 [==============================] - 1s 984us/step - loss: 1393447.5000\n",
            "Epoch 273/300\n",
            "1259/1259 [==============================] - 1s 996us/step - loss: 1393449.0000\n",
            "Epoch 274/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1393336.3750\n",
            "Epoch 275/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1393231.1250\n",
            "Epoch 276/300\n",
            "1259/1259 [==============================] - 1s 990us/step - loss: 1393161.6250\n",
            "Epoch 277/300\n",
            "1259/1259 [==============================] - 1s 993us/step - loss: 1393098.5000\n",
            "Epoch 278/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1392897.2500\n",
            "Epoch 279/300\n",
            "1259/1259 [==============================] - 1s 997us/step - loss: 1392992.8750\n",
            "Epoch 280/300\n",
            "1259/1259 [==============================] - 1s 999us/step - loss: 1392892.3750\n",
            "Epoch 281/300\n",
            "1259/1259 [==============================] - 1s 988us/step - loss: 1392787.0000\n",
            "Epoch 282/300\n",
            "1259/1259 [==============================] - 1s 980us/step - loss: 1392776.1250\n",
            "Epoch 283/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1392629.3750\n",
            "Epoch 284/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1392650.8750\n",
            "Epoch 285/300\n",
            "1259/1259 [==============================] - 1s 991us/step - loss: 1392595.0000\n",
            "Epoch 286/300\n",
            "1259/1259 [==============================] - 1s 998us/step - loss: 1392484.0000\n",
            "Epoch 287/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1392403.5000\n",
            "Epoch 288/300\n",
            "1259/1259 [==============================] - 1s 981us/step - loss: 1392388.6250\n",
            "Epoch 289/300\n",
            "1259/1259 [==============================] - 1s 1000us/step - loss: 1392298.1250\n",
            "Epoch 290/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1392198.2500\n",
            "Epoch 291/300\n",
            "1259/1259 [==============================] - 1s 997us/step - loss: 1392234.2500\n",
            "Epoch 292/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1392162.3750\n",
            "Epoch 293/300\n",
            "1259/1259 [==============================] - 1s 988us/step - loss: 1392070.7500\n",
            "Epoch 294/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1392041.0000\n",
            "Epoch 295/300\n",
            "1259/1259 [==============================] - 1s 1000us/step - loss: 1392026.3750\n",
            "Epoch 296/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1391943.6250\n",
            "Epoch 297/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1391879.1250\n",
            "Epoch 298/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1391850.6250\n",
            "Epoch 299/300\n",
            "1259/1259 [==============================] - 1s 990us/step - loss: 1391768.6250\n",
            "Epoch 300/300\n",
            "1259/1259 [==============================] - 1s 1ms/step - loss: 1391685.3750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei4B_FKfPk3h"
      },
      "source": [
        "#step6: Prediction\n",
        "ypred=ann.predict(xtest)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LB3ykodQnHK",
        "outputId": "691589a0-8791-4f5b-ae50-d86403fefadc"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score(ytest,ypred)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.919412962833745"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVz81HY_Qrrc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}